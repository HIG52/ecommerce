# Redis 기반 인메모리를 활용한 선착순 쿠폰 발급 로직 개선

---

## 1. 배경

선착순 쿠폰 발급 기능은 많은 사용자가 동시에 접근하는 이벤트 상황에서 높은 트래픽을 발생할 수 있다.  
기존 시스템에서는 DB의 비관적 락을 사용하여 쿠폰 재고를 하나씩 감소시키고, 사용자별 쿠폰 발급 내역을 기록하는 방식으로 운영됨.

그러나 이러한 방식은 동시 접근 시 DB 부하와 락 경합으로 인해 성능 저하 및 응답 지연 현상이 발생.
따라서 Redis를 활용하여 재고를 미리 메모리에 적재하였고, 요청마다 메모리 상에서 재고를 차감한 후 성공 시 DB에 기록하는 방식으로 로직을 변경하였음.

---

## 2. 문제

- **DB 비관적 락 방식의 한계**
    - 다수의 동시 요청 시 DB 락 경합으로 성능 저하와 응답 지연이 발생.
    - DB 자원에 대한 부담이 증가

- **실시간 응답 지연**
    - 쿠폰 재고 조회 및 감소를 위해 반복적으로 DB에 접근한 결과 응답 속도가 느려진다.

- **응답 지연으로 인한 불쾌한 사용자 경험 발생**
    - 이벤트 기간 다수의 사용자가 동시에 요청함에 따라 DB에 응답이 점점 지연되고 이는 곧 사용자의 경험이 불쾌해질수 있음

---

## 3. 현재 시스템(As-Is) 분석

### 기존 로직 (비관적 락 기반 DB 접근)
- **재고 조회**:
    - 쿠폰 정보를 DB를 조회하여 가져오면서 비관적락을 사용.
- **재고 관리**:
    - 쿠폰 재고를 DB에서 관리하였고, 재고를 하나씩 감소.
- **사용자 발급 내역 기록**:
    - 매번 DB의 유저쿠폰 테이블에 발급 내역을 기록하였음.
- **문제점**:
    - 동시 요청 시 DB 락 경합으로 인해 응답 지연 및 시스템 부하가 증가.
    - 수많은 요청시 응답대기 시간이 점점 증가함.

---

## 4. 개선 방안 (To-Be)

### Redis를 활용한 캐시 기반 재고 관리 로직
- **재고 선적재**:
    - 이벤트 시작 전 또는 시스템 초기화 시 Redis에 쿠폰 재고를 미리 적재하여 메모리 상에 보관.
- **실시간 재고 감소**:
    - 사용자가 쿠폰 발급 요청 시 Redis의 메모리 상 재고 값을 원자적 연산(Lua 스크립트)을 통해 차감.
    - 재고가 충분할 경우에만 DB의 유저쿠폰 테이블에 발급 내역을 기록하여 정합성을 보장.
- **기대 효과**:
    - DB 접근 횟수를 크게 줄여 동시성 문제를 완화하였음. 
    - 기존 조회, 차감, 발급 최소 3번이상 db에 접근하는것을 발급한번으로 최소화.
    - 메모리 기반 처리로 응답 속도를 향상시키고 시스템 확장성을 개선.
    - 빠른 응답으로 사용자 경험 개선.
---

> **참고**: 본 개선안에서는 쿠폰 재고의 빠른 접근 및 원자적 감소가 필요하였기에,  
> **Read-Through** 개념(읽기작업을 우선 수행)과 원자적 연산을 활용하여 Redis를 사용한 방식이 적합하다고 판단하였기에 캐싱을 사용하지 않았음

## 5. 캐시 개념 및 캐시 전략 4가지

### 5.1. 캐시란?
- **정의**:  
  자주 사용하는 데이터나 값을 미리 복사해 놓는 임시 장소를 가리킨다.
- **장점**:  
  빠른 성능을 제공한다.
- **단점**:  
  저장 공간이 작고 비용이 비싸다. 

### 5.2. 캐시 전략
#### 캐시 읽기 전략 (Read Cache Strategy)
1. **Look Aside (Cache-Aside)**
    - **설명**: 데이터를 찾을때 캐시에 저장된 데이터가 있는지 우선적으로 확인하는 전략, 없을시 DB에서 조회
    - **상황**: 반복적인 읽기 작업이 많을경우 사용
    - **장단점**: 캐시와 DB가 분리되어 가용되기 때문에 원하는 데이터만 별도 구성하여 캐시에 저장, 또한 캐시 장애 대비 구성이 되어있다. 하지만 redis가 다운된다면 순간적으로 DB로 요청이몰려서 부하가 발생할수도 있다(캐시 스탬피드)  
                    

2. **Read-Through**
    - **설명**: 데이터 동기화를 라이브러리 또는 캐시 제공자에게 위임하는 방식 Look Aside와 비슷
    - **상황**: 읽기 요청이 빈번하며 데이터 변경이 상대적으로 적은 경우에 활용
    - **장단점**: 캐시와 DB간의 데이터 동기화가 항상 이루어져 정합성 문제에서 자유로움, 하지만 캐시의 의존도가 높아 캐시를 구현한 redis등의 시스템이 다운될경우 서비스 이용에 차질이 생길수도 있다.

#### 캐시 읽기 전략 (Write Cache Strategy)
1. **Write Back (Write Behind)**
    - **설명**: 데이터를 저장할때 DB에 바로저장하지 않고 캐시에 모아서 일정주기로 DB에 반영
    - **상황**: 쓰기 작업이 빈번하면서 읽기를 하는데 많은양의 리소스가 소모될때 사용
    - **장단점**: 데이터의 정합성을 확보할수 있고, 동기화 과정이 생락된다. 하지만 자주 사용되지 않는 불필요한 리소스를 저장하고 캐시에 오류가 생길경우 데이터를 영구 소실할수 있다.

2. **Write Through**
    - **설명**: DB와 캐시를 동시에 데이터를 저장한다. 
    - **상황**: 데이터 유실이 발생하면 안되는 상황에 사용
    - **장단점**: 데이터의 일관성을 유지할수 있다. 하지만 불필요한 리소스를 저장하게 되고, 빈번한 생성, 수정이 발생하는 서비스에서 성능이슈가 생길수도 있다.

3. **Write Around**
    - **설명**: 모든 데이터는 DB에 저장(캐시 갱신을 하지 않음)
    - **상황**: 데이터가 한 번 쓰여지고, 덜 자주 읽히거나 읽지 않는 상황에서 사용한다.
    - **장단점**: Write Through 보다 훨씬 빠른 성능을 가지고 있다, 다만 캐시를 갱신하지 않기에 캐시와 DB의 데이터가 다를수 있다.

_해당 방법들 말고도, 캐시 읽기 + 쓰기 전략의 조합으로 Look Aside + Write Around 등의 전략을 합치고 섞어서 좀더 좋은 성능과 시너지등을 만들어 낼수 있다._

---

## 6. 캐시스탬피드(Cache Stampede) 현상

- **개념**:  
  캐시 만료 시 다수의 요청이 동시에 DB에 접근하여 DB에 과부화를 가져오는 현상
- **문제점**:  
  DB에 과도한 부하가 발생하여 전체 시스템 성능이 저하되고 장애 위험이 증가하였음.
- **대응 방안**:
    - **적절한 만료 시간 설정**: 만료시간을 너무 짧게 설정하지 말고 데이터 특성에 맞춰서 설정한다
    - **선 계산**: 키가 만료되기 전에 미리 값을 갱신한다.
    - **확률적 접근**: 만료시간이 가까워질수록 확률적으로 DB에 접근해 데이터를 갱신한다.
    - **PER 알고리즘**: 확률적 조기 재계산(Probabilistic Early Recompilation) 알고리즘을 사용한다.

_확률적 접근과 PER 알고리즘은 단순 방법적으로 캐시 만료시간을 랜덤하게 설정하느냐 캐시가 만료되기 전에 일정 확률로 미리 캐시를 갱신하느냐의 방법적인 차이만 존재하고 장단점의 큰차이는 존재하지 않는다._

---

## 9. 결론

기존 DB의 비관적 락 기반 선착순 쿠폰 발급 로직을 Redis를 활용하여 재고를 메모리에 선적재하고,  
요청마다 원자적 연산으로 재고를 차감하는 방식으로 개선하여 성능의 유의미한 향상을 하였음

- **주요 개선 포인트**:
    - Redis를 활용한 메모리 기반 재고 관리로 DB 부하를 감소시키고 응답 속도를 향상시켰음.
    - 캐시 전략 중 Read-Through 개념과 원자적 연산을 활용하여 높은 동시성 상황에서도 안정적인 서비스를 제공.

이와 같은 개선을 통해 조회가 오래 걸리거나 DB에 과도한 부하가 발생하는 상황에서,  
캐시(또는 인메모리 저장소)를 활용한 로직 이관이 왜 효과적이었는지를 확인하였음.

추후 다른 기능(상위 상품 조회같은 통계쿼리) 에 관해서는 캐싱을 적용하여 비동기로 일정 주기에 한번씩 캐시에 넣어주어 
호출시마다 계산하는거보다 더 빠른 제공을 위해 개선할 예정.
